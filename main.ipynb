{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting np_utils\n",
      "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
      "     -------------------------------------- 62.0/62.0 kB 834.6 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.0 in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from np_utils) (1.25.0)\n",
      "Building wheels for collected packages: np_utils\n",
      "  Building wheel for np_utils (setup.py): started\n",
      "  Building wheel for np_utils (setup.py): finished with status 'done'\n",
      "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56448 sha256=c0d583ed68770c9a5143ae0d89a43d99726f6125b22bb7bce31e91aa832f2c81\n",
      "  Stored in directory: c:\\users\\nitish\\appdata\\local\\pip\\cache\\wheels\\58\\f9\\8a\\124b12d81a2f299073c25fbc0a99c5d13224db6c55351d744a\n",
      "Successfully built np_utils\n",
      "Installing collected packages: np_utils\n",
      "Successfully installed np_utils-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement keras.utils.np_utils (from versions: none)\n",
      "ERROR: No matching distribution found for keras.utils.np_utils\n"
     ]
    }
   ],
   "source": [
    "pip install keras.utils.np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\program files\\python311\\lib\\site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "     ---------------------------------------- 1.8/1.8 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-24.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.utils.np_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.np_utils'"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras.utils\n",
      "  Downloading keras-utils-1.0.13.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Keras>=2.1.5 in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from keras.utils) (3.6.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from Keras>=2.1.5->keras.utils) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from Keras>=2.1.5->keras.utils) (1.25.0)\n",
      "Requirement already satisfied: rich in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from Keras>=2.1.5->keras.utils) (13.9.2)\n",
      "Requirement already satisfied: namex in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from Keras>=2.1.5->keras.utils) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from Keras>=2.1.5->keras.utils) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from Keras>=2.1.5->keras.utils) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from Keras>=2.1.5->keras.utils) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from Keras>=2.1.5->keras.utils) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from optree->Keras>=2.1.5->keras.utils) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from rich->Keras>=2.1.5->keras.utils) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from rich->Keras>=2.1.5->keras.utils) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->Keras>=2.1.5->keras.utils) (0.1.2)\n",
      "Building wheels for collected packages: keras.utils\n",
      "  Building wheel for keras.utils (setup.py): started\n",
      "  Building wheel for keras.utils (setup.py): finished with status 'done'\n",
      "  Created wheel for keras.utils: filename=keras_utils-1.0.13-py3-none-any.whl size=2655 sha256=f368b60ec595ea1f20598ff276b19bd92e932fdc1fb6178a8480bd438937ed5d\n",
      "  Stored in directory: c:\\users\\nitish\\appdata\\local\\pip\\cache\\wheels\\84\\04\\c8\\f3d21e09aa3a1e25bc4a4fc07341ca073d7372f33dbd344a06\n",
      "Successfully built keras.utils\n",
      "Installing collected packages: keras.utils\n",
      "Successfully installed keras.utils-1.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip install keras.utils \n",
    "# tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.src.utils.numerical_utils.to_categorical(x, num_classes=None)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "from tf.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\nitish\\appdata\\roaming\\python\\python311\\site-packages (from opencv-python) (1.25.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "tf.keras.utils.to_categorical\n",
    "from keras.layers import Dropout, Flatten\n",
    "# from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "!pip install opencv-python\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.keras.utils.to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D, MaxPooling2D, Dropout, Flatten\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.23.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes Detected: 43\n",
      "Importing Classes.....\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (38969,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m classNo \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(classNo)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (38969,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "path = \"Dataset\" \n",
    "labelFile = 'labels.csv' \n",
    "batch_size_val = 32\n",
    "# batch_size_val=50\n",
    "# steps_per_epoch_val = 2000 \n",
    "epochs_val=10\n",
    "imageDimesions = (32,32,3)\n",
    "testRatio = 0.2    \n",
    "validationRatio = 0.2 \n",
    "\n",
    "count = 0\n",
    "images = []\n",
    "classNo = []\n",
    "myList = os.listdir(path)\n",
    "print(\"Total Classes Detected:\",len(myList))\n",
    "noOfClasses=len(myList)\n",
    "print(\"Importing Classes.....\")\n",
    "for x in range (0,len(myList)-1):\n",
    "    myPicList = os.listdir(path+\"/\"+str(count))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
    "        images.append(curImg)\n",
    "        classNo.append(count)\n",
    "    print(count, end =\" \")\n",
    "    count +=1\n",
    "print(\" \")\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shapes\n",
      "Train"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m);\u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape,y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m,end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m);\u001b[38;5;28mprint\u001b[39m(X_validation\u001b[38;5;241m.\u001b[39mshape,y_validation\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m,end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m);\u001b[38;5;28mprint\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape,y_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Data Shapes\")\n",
    "print(\"Train\",end = \"\");print(X_train.shape,y_train.shape)\n",
    "print(\"Validation\",end = \"\");print(X_validation.shape,y_validation.shape)\n",
    "print(\"Test\",end = \"\");print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/70238017/pickle-dumpmodel-pickle-out-typeerror-cant-pickle-thread-local-objects\n",
    "\n",
    "\n",
    "https://github.com/Chando0185/traffic_sign_recognition/blob/main/Traffic_Sign_Recognition.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape  (43, 2) <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(labelFile)\n",
    "print(\"data shape \",data.shape,type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "num_of_samples = []\n",
    "cols = 5\n",
    "num_classes = noOfClasses\n",
    "\n",
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "def equalize(img):\n",
    "    img =cv2.equalizeHist(img)\n",
    "    return img\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)     \n",
    "    img = equalize(img)      \n",
    "    img = img/255            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (24940,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpreprocessing\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      2\u001b[0m X_validation\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(preprocessing,X_validation)))\n\u001b[0;32m      3\u001b[0m X_test\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(preprocessing,X_test)))\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (24940,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "X_train=np.array(list(map(preprocessing,X_train)))  \n",
    "X_validation=np.array(list(map(preprocessing,X_validation)))\n",
    "X_test=np.array(list(map(preprocessing,X_test)))\n",
    "\n",
    "\n",
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_validation=X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
